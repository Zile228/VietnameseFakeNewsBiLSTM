{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from underthesea import sent_tokenize\n",
    "from underthesea import word_tokenize\n",
    "import re\n",
    "df = pd.read_json('news_dataset.json')\n",
    "df = df['content']\n",
    "df = df.sample(frac = 0.5, random_state=42, ignore_index=True)\n",
    "df = df.drop_duplicates(ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = stopwords = [\"bị\", \"bởi\", \"cả\", \"các\", \"cái\", \"cần\", \"càng\", \"chỉ\", \"chiếc\", \"cho\", \"chứ\", \"chưa\", \"chuyện\", \"có\", \"có_thể\", \"cứ\", \"của\", \"cùng\", \"cũng\", \"đã\", \"đang\", \"đây\", \"để\", \"đến_nỗi\", \"đều\", \"điều\", \"do\", \"đó\", \"được\", \"dưới\", \"gì\", \"khi\", \"không\", \"là\", \"lại\", \"lên\", \"lúc\", \"mà\", \"mỗi\", \"một_cách\", \"này\", \"nên\", \"nếu\", \"ngay\", \"nhiều\", \"như\", \"nhưng\", \"những\", \"nơi\", \"nữa\", \"phải\", \"qua\", \"ra\", \"rằng\", \"rằng\", \"rất\", \"rất\", \"rồi\", \"sau\", \"sẽ\", \"so\", \"sự\", \"tại\", \"theo\", \"thì\", \"trên\", \"trước\", \"từ\", \"từng\", \"và\", \"vẫn\", \"vào\", \"vậy\", \"vì\", \"việc\", \"với\", \"vừa\"]\n",
    "\n",
    "sent = set()\n",
    "## Sentence tokenization\n",
    "for i in range(len(df)):\n",
    "    sentence = sent_tokenize(df.loc[i])\n",
    "    for s in sentence:\n",
    "        sent.add(s)\n",
    "sent = list(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100000, len(sent)):\n",
    "    sent[i] = re.sub('[\\W]', ' ', sent[i].lower())\n",
    "    tokens = []\n",
    "    for t in word_tokenize(sent[i]):\n",
    "        t = t.replace(\" \", \"_\")\n",
    "        if t not in stopwords:\n",
    "            tokens.append(t)\n",
    "    sent[i] = tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dữ liệu đã được lưu tại array_data.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "file_path = 'array_data.json'\n",
    "\n",
    "with open(file_path, mode='w', encoding='utf-8') as file:\n",
    "    json.dump(sent, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"Dữ liệu đã được lưu tại {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from gensim.models import Word2Vec\n",
    "# Đọc dữ liệu từ file JSON\n",
    "with open('array_data.json', mode='r', encoding='utf-8') as file:\n",
    "    sent = json.load(file)\n",
    "# Huấn luyện mô hình Word2Vec\n",
    "pretrained_model = Word2Vec(\n",
    "    sentences=sent,  # Dữ liệu huấn luyện\n",
    "    vector_size=300,            # Số chiều vector nhúng\n",
    "    window=3,                   # Cửa sổ ngữ cảnh\n",
    "    min_count=3,                # Bỏ qua các từ xuất hiện < 3 lần\n",
    "    sg=1,                       # Sử dụng Skip-gram\n",
    "    hs=0,                       # Không dùng hierarchical softmax\n",
    "    negative=10,                # Số mẫu âm tính\n",
    "    epochs=10,                  # Số vòng lặp qua dữ liệu\n",
    "    workers=3                  # Số luồng xử lý\n",
    ")\n",
    "# Lưu mô hình\n",
    "pretrained_model.save(\"pretrained_word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('nam_sinh', 0.6152075529098511),\n",
       " ('thảo_ngân', 0.5380651354789734),\n",
       " ('học_sinh', 0.527435839176178),\n",
       " ('em', 0.5261192321777344),\n",
       " ('đăng_khải', 0.5126875042915344),\n",
       " ('nữ_sinh_học', 0.5105963349342346)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_model.wv.most_similar(positive=\"nữ_sinh\", topn = 6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
